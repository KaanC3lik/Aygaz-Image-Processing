{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaanC3lik/Aygaz-Image-Processing/blob/main/goruntu_isleme_bootcamp_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "rrebirrth_animals_with_attributes_2_path = kagglehub.dataset_download('rrebirrth/animals-with-attributes-2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "MDGKTUZmCtsD",
        "outputId": "75d82351-4ed6-452d-db35-80f549a3bea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rrebirrth/animals-with-attributes-2?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.0G/13.0G [02:37<00:00, 88.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "I changed the code to save the first 650 images of each animal species."
      ],
      "metadata": {
        "id": "Z5WWIbr-0zgn"
      }
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "5FOPNGRFCtsD",
        "outputId": "83786c92-576e-47b6-bfa3-0951913bcb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Initialize the dictionary to hold paths for each animal\n",
        "image_paths = {}\n",
        "\n",
        "# Base directory for your dataset\n",
        "base_path = \"/root/.cache/kagglehub/datasets/rrebirrth/animals-with-attributes-2/versions/1/Animals_with_Attributes2/JPEGImages/\"\n",
        "\n",
        "# List of animals to search for\n",
        "animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
        "\n",
        "# Traverse the directory structure\n",
        "for dirname, _, filenames in os.walk(base_path):\n",
        "    for animal in animals:\n",
        "        # Check if the current directory contains the animal's name\n",
        "        if animal in dirname:\n",
        "            # Initialize the list if the animal is encountered for the first time\n",
        "            if animal not in image_paths:\n",
        "                image_paths[animal] = []\n",
        "            # Add 650 image paths for the current animal\n",
        "            for filename in filenames:\n",
        "                if len(image_paths[animal]) < 650:\n",
        "                  image_paths[animal].append(os.path.join(dirname, filename))\n",
        "                else:\n",
        "                  break\n",
        "\n",
        "\n",
        "\n",
        "# Print the paths for verification\n",
        "for animal, paths in image_paths.items():\n",
        "    print(f\"{animal}: {len(paths)} images\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giant+panda: 650 images\n",
            "elephant: 650 images\n",
            "polar+bear: 650 images\n",
            "rabbit: 650 images\n",
            "moose: 650 images\n",
            "dolphin: 650 images\n",
            "squirrel: 650 images\n",
            "fox: 650 images\n",
            "sheep: 650 images\n",
            "collie: 650 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The load_and_preprocess_images function is designed to handle image datasets organized by categories. It takes as input a dictionary of image paths categorized by class and a target size for resizing the images. Each image is read using OpenCV, resized to a uniform shape (64x64 pixels in this case), and normalized to scale pixel values to a range of [0, 1]. Normalization improves the training process by ensuring that all pixel values have the same scale, which can help the model converge faster."
      ],
      "metadata": {
        "id": "FmGSSP8lO3kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define a function to load and preprocess images\n",
        "def load_and_preprocess_images(image_paths, image_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for animal, paths in image_paths.items():\n",
        "        for img_path in paths:\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Normalize pixel values to the range [0, 1]\n",
        "            if img is not None:\n",
        "                img_resized = cv2.resize(img, image_size)\n",
        "                img_normalized = img_resized / 255.0\n",
        "                data.append(img_normalized)\n",
        "                labels.append(animal)\n",
        "\n",
        "    return np.array(data), np.array(labels)  # Convert lists to NumPy arrays and return"
      ],
      "metadata": {
        "id": "GiHpypVbbDeb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (64, 64)\n",
        "\n",
        "# Load and preprocess images using the specified image paths\n",
        "X, y = load_and_preprocess_images(image_paths, image_size)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "7NhPACcduepo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A LabelEncoder is then used to convert the class labels (animal names) into numerical format, with one-hot encoding."
      ],
      "metadata": {
        "id": "M5kRtWwssIdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder to convert animal names to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(animals)\n",
        "\n",
        "# Transform y_train and y_test to numerical labels\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encoding (Modelin kullanması için etiketleri dönüştür)\n",
        "y_train_onehot = to_categorical(y_train_encoded, num_classes=len(animals))\n",
        "y_test_onehot = to_categorical(y_test_encoded, num_classes=len(animals))\n"
      ],
      "metadata": {
        "id": "P_97O4XYuRKX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialized an image data generator for data augmentation.\n",
        "Data augmentation is performed using the ImageDataGenerator class, which applies random transformations such as rotations, translations, zooming, and horizontal flips to enhance the diversity of the training data."
      ],
      "metadata": {
        "id": "8hgbKs0quaom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Create a training data generator that applies data augmentation\n",
        "batch_size = 32\n",
        "train_generator = datagen.flow(X_train, y_train_onehot, batch_size=batch_size)\n",
        "\n",
        "\n",
        "for X_batch, y_batch in train_generator:\n",
        "    print(f\"A batch produced by data augmentation: {X_batch.shape}, Labels: {y_batch.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jarVXkEEdKto",
        "outputId": "7a6f658d-6c82-4fbd-e2e6-fce298021096"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A batch produced by data augmentation: (32, 64, 64, 3), Labels: (32, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   This code defines a Convolutional Neural Network (CNN) architecture designed to classify images into 10 animal categories. The model begins with an input layer configured for images of size 64x64x3, which corresponds to RGB images.\n",
        "*    The first layer is a convolutional layer with 32 filters of size 3x3, followed by a ReLU activation function to introduce non-linearity. This layer is paired with a MaxPooling layer, which reduces the spatial dimensions of the feature maps while preserving their most important features.\n",
        "*   After the convolutional and pooling layers, the feature maps are flattened into a one-dimensional vector, allowing the data to pass into fully connected layers. A dense layer with 128 units and ReLU activation is used to further process the extracted features.\n",
        "*   To prevent overfitting, a Dropout layer with a rate of 0.5 is applied, randomly setting half of the neurons to zero during training.\n",
        "\n",
        "*    The final layer consists of 10 units (one for each animal class) with a softmax activation function, which converts the output into probabilities for each class.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4ZEDWu8otgdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "input_shape = (64, 64, 3) # Image size (height, width, channels)\n",
        "num_classes = 10 # For classification 10 classes\n",
        "conv_filters = 32 # Number of filters for convolution layers\n",
        "kernel_size = (3, 3) # Size of the convolution kernel\n",
        "pool_size = (2, 2) # Size of the pooling layer\n",
        "dense_units = 128 # Number of units in the fully connected layer\n",
        "learning_rate = 0.001 # Learning rate for the optimizer\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1. Convolutional Layer\n",
        "model.add(Conv2D(conv_filters, kernel_size, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size))  # 1. Pooling Layer\n",
        "\n",
        "# 2. Convolutional Layer\n",
        "model.add(Conv2D(conv_filters*2, kernel_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size))  # 2. Pooling Layer\n",
        "\n",
        "# 3. Convolutional Layer\n",
        "model.add(Conv2D(conv_filters*3, kernel_size, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size))  # 3. Pooling Layer\n",
        "\n",
        "# 4. Fully Connected Layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(len(animals), activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "IyLc7nb6jLac",
        "outputId": "c1f481e1-bff1-42cc-fb92-2ce72b2b3fd3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │          \u001b[38;5;34m55,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m96\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3456\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m442,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3456</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m518,570\u001b[0m (1.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">518,570</span> (1.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m518,570\u001b[0m (1.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">518,570</span> (1.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   The optimizer is set to Adam with a learning rate of 0.001.\n",
        "Adam is an adaptive learning rate optimization algorithm that computes individual learning rates for each parameter, which generally leads to faster convergence.\n",
        "*   Choosed Categorical cross-entropy for loss function. Because it is commonly used for multi-class classification problems where the labels are one-hot encoded\n",
        "\n"
      ],
      "metadata": {
        "id": "kmELKzva7SYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yl4Vp36anPn8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained the model with augmented data in 20 epoch. Model's accuracy is 0.66"
      ],
      "metadata": {
        "id": "59JLMO7e7cUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli eğitme\n",
        "epochs = 20  # Eğitim adım sayısı (epoch)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(X_test, y_test_onehot))  # Validation data kullanarak değerlendirme\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QINyQMe_nSSI",
        "outputId": "d1b71c80-7bd0-4102-d272-a609f5592b63"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 266ms/step - accuracy: 0.4736 - loss: 1.5089 - val_accuracy: 0.5621 - val_loss: 1.2959\n",
            "Epoch 2/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 1.4741 - val_accuracy: 0.5677 - val_loss: 1.2744\n",
            "Epoch 3/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 267ms/step - accuracy: 0.4950 - loss: 1.4681 - val_accuracy: 0.5733 - val_loss: 1.2332\n",
            "Epoch 4/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.4375 - loss: 1.5893 - val_accuracy: 0.5656 - val_loss: 1.2399\n",
            "Epoch 5/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 280ms/step - accuracy: 0.4878 - loss: 1.4407 - val_accuracy: 0.5928 - val_loss: 1.2235\n",
            "Epoch 6/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5312 - loss: 1.5584 - val_accuracy: 0.5856 - val_loss: 1.2121\n",
            "Epoch 7/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 281ms/step - accuracy: 0.5462 - loss: 1.3583 - val_accuracy: 0.6174 - val_loss: 1.1355\n",
            "Epoch 8/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4375 - loss: 1.4246 - val_accuracy: 0.6205 - val_loss: 1.1218\n",
            "Epoch 9/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 277ms/step - accuracy: 0.5442 - loss: 1.3254 - val_accuracy: 0.6021 - val_loss: 1.1746\n",
            "Epoch 10/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4375 - loss: 1.3364 - val_accuracy: 0.5944 - val_loss: 1.1846\n",
            "Epoch 11/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 277ms/step - accuracy: 0.5547 - loss: 1.3009 - val_accuracy: 0.6133 - val_loss: 1.1545\n",
            "Epoch 12/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4375 - loss: 1.6496 - val_accuracy: 0.6118 - val_loss: 1.1578\n",
            "Epoch 13/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 279ms/step - accuracy: 0.5483 - loss: 1.2852 - val_accuracy: 0.6262 - val_loss: 1.0942\n",
            "Epoch 14/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4375 - loss: 1.2137 - val_accuracy: 0.6349 - val_loss: 1.0911\n",
            "Epoch 15/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 280ms/step - accuracy: 0.5757 - loss: 1.2594 - val_accuracy: 0.6477 - val_loss: 1.0403\n",
            "Epoch 16/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6562 - loss: 1.0433 - val_accuracy: 0.6472 - val_loss: 1.0428\n",
            "Epoch 17/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 279ms/step - accuracy: 0.5866 - loss: 1.2036 - val_accuracy: 0.6400 - val_loss: 1.0209\n",
            "Epoch 18/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.7552 - val_accuracy: 0.6385 - val_loss: 1.0379\n",
            "Epoch 19/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 278ms/step - accuracy: 0.5917 - loss: 1.2125 - val_accuracy: 0.6615 - val_loss: 1.0074\n",
            "Epoch 20/20\n",
            "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5312 - loss: 1.2693 - val_accuracy: 0.6646 - val_loss: 0.9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linearize_image(image):\n",
        "    \"\"\"\n",
        "    Converts an sRGB image to linear RGB assuming the input image is in the range [0, 1]\n",
        "    \"\"\"\n",
        "    return np.where(image <= 0.04045,\n",
        "                    image / 12.92,\n",
        "                    ((image + 0.055) / 1.055) ** 2.4)\n",
        "\n",
        "\n",
        "def linear_to_srgb(image):\n",
        "    \"\"\"\n",
        "    Converts a linear RGB image to sRGB assuming the input image is in the range [0, 1]\n",
        "    \"\"\"\n",
        "    return np.where(image <= 0.0031308,\n",
        "                    image * 12.92,\n",
        "                    1.055 * (image ** (1 / 2.4)) - 0.055)\n",
        "\n",
        "\n",
        "def handle_saturation(image, lower=0.05, upper=0.95):\n",
        "    \"\"\"\n",
        "    Creates a mask for non-saturated pixels (those between `lower` and `upper` thresholds)\n",
        "    \"\"\"\n",
        "    return np.all((image > lower) & (image < upper), axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "### Color constancy\n",
        "def estimate_light_source_grey_world(image, mask):\n",
        "    \"\"\"\n",
        "    Estimates the light source based on the Grey World assumption, using valid pixels from the mask\n",
        "    \"\"\"\n",
        "    valid_pixels = image[mask]\n",
        "    avg_color = np.mean(valid_pixels, axis=0)\n",
        "    return avg_color / np.linalg.norm(avg_color)\n",
        "\n",
        "\n",
        "def correct_colors(image, light_source):\n",
        "    \"\"\"\n",
        "    Corrects the colors of the image by applying white balance using the estimated light source\n",
        "    \"\"\"\n",
        "    return image * (1.0 / light_source)\n",
        "\n",
        "\n",
        "def manipulate_light_source(image, light_color):\n",
        "    \"\"\"\n",
        "    Simulates color manipulation under a different light source\n",
        "\n",
        "    Args:\n",
        "    - image: The input image (sRGB, [0, 1])\n",
        "    - light_color: The light source color (unit norm RGB vector)\n",
        "\n",
        "    Returns:\n",
        "    - Manipulated image (sRGB, [0, 1])\n",
        "    \"\"\"\n",
        "    # Step 1: Linearize the image\n",
        "    linear_image = linearize_image(image)\n",
        "\n",
        "    # Step 2: Apply the light source (multiplying the linear image by the light color)\n",
        "    manipulated_image = linear_image * light_color\n",
        "\n",
        "    # Step 3: Convert the manipulated image back to sRGB\n",
        "    manipulated_srgb = linear_to_srgb(manipulated_image)\n",
        "\n",
        "    return np.clip(manipulated_srgb, 0, 1)\n",
        "\n",
        "\n",
        "def process_and_white_balance(image):\n",
        "    \"\"\"\n",
        "    Applies white balance using both the Grey World and Max RGB methods\n",
        "    Returns both corrected images in sRGB format\n",
        "    \"\"\"\n",
        "    linear_image = linearize_image(image)\n",
        "    valid_mask = handle_saturation(linear_image)\n",
        "\n",
        "    # Light source estimations\n",
        "    grey_world_light = estimate_light_source_grey_world(linear_image, valid_mask)\n",
        "\n",
        "    # Color correction using both light sources\n",
        "    corrected_grey_world = correct_colors(linear_image, grey_world_light)\n",
        "\n",
        "    # Convert back to sRGB\n",
        "    srgb_grey_world = linear_to_srgb(corrected_grey_world)\n",
        "\n",
        "    # Clip and return\n",
        "    return np.clip(srgb_grey_world, 0, 1)\n",
        "\n",
        "\n",
        "# Light sources for color manipulation\n",
        "def get_light_sources():\n",
        "    \"\"\"\n",
        "    Returns a set of light sources for image manipulation\n",
        "    \"\"\"\n",
        "    purplish_light = np.array([0.82, 0.15, 0.89]) / np.linalg.norm([0.82, 0.15, 0.89])\n",
        "    yellowish_light = np.array([0.96, 0.24, 0.11]) / np.linalg.norm([0.96, 0.24, 0.11])\n",
        "    greenish_light = np.array([0.11, 0.98, 0.12]) / np.linalg.norm([0.11, 0.98, 0.12])\n",
        "    return purplish_light, yellowish_light, greenish_light\n",
        "\n",
        "\n",
        "def get_wb_images(image):\n",
        "    \"\"\"\n",
        "    Process and white balance the image\n",
        "    \"\"\"\n",
        "\n",
        "    srgb_grey_world = process_and_white_balance(image)\n",
        "\n",
        "    # Save the white-balanced images\n",
        "    #cv2.imwrite('white_balanced_grey_world.jpg', cv2.cvtColor((srgb_grey_world*255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "    return srgb_grey_world\n",
        "\n",
        "\n",
        "def get_manipulated_images(image):\n",
        "    \"\"\"\n",
        "    Get manipulated images by applying color vectors\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the color vectors\n",
        "    purplish_light, orangish_light, greenish_light = get_light_sources()\n",
        "\n",
        "    # Manipulate the images under different light sources\n",
        "    manipulated_purplish = manipulate_light_source(image, purplish_light)\n",
        "    manipulated_orangish = manipulate_light_source(image, orangish_light)\n",
        "    manipulated_greenish = manipulate_light_source(image, greenish_light)\n",
        "\n",
        "    # Save the manipulated images\n",
        "    #cv2.imwrite('manipulated_purplish.jpg', cv2.cvtColor((manipulated_purplish*255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "    #cv2.imwrite('manipulated_orangish.jpg', cv2.cvtColor((manipulated_orangish*255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "    #cv2.imwrite('manipulated_greenish.jpg', cv2.cvtColor((manipulated_greenish*255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "    return manipulated_purplish, manipulated_orangish, manipulated_greenish\n"
      ],
      "metadata": {
        "id": "Xa1Ms2SFojrP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code manipulates the test images by applying three different color filters (purplish, orangish, and greenish) to each image in the test set. For each manipulated image, the corresponding label is repeated, and the new images are added to the test set. After manipulation, the new test set and labels are returned as NumPy array."
      ],
      "metadata": {
        "id": "zet33CXv9kQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manipulate_test_images(X_test, y_test):\n",
        "\n",
        "    manipulated_test_set = []\n",
        "    manipulated_labels = []\n",
        "\n",
        "    for img, label in zip(X_test, y_test_onehot):\n",
        "        # Get manipulated images\n",
        "        manipulated_purplish, manipulated_orangish, manipulated_greenish = get_manipulated_images(img)\n",
        "\n",
        "        # Add manipulted images in dictionary with it's labels\n",
        "        manipulated_test_set.extend([manipulated_purplish, manipulated_orangish, manipulated_greenish])\n",
        "        manipulated_labels.extend([label, label, label])\n",
        "\n",
        "    return np.array(manipulated_test_set), np.array(manipulated_labels)\n",
        "\n",
        "\n",
        "manipulated_test_set, manipulated_labels = manipulate_test_images(X_test, y_test)\n",
        "\n",
        "print(f\"Manipulated test set size: {manipulated_test_set.shape}\")\n",
        "print(f\"Manipulated label size: {manipulated_labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fI66-hesMBT",
        "outputId": "bd81dde5-22da-43cd-abb4-d5a8aba5d199"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manipulated test set size: (5850, 64, 64, 3)\n",
            "Manipulated label size: (5850, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating new manipulated images with our model. After manipulating images our model's new accuracy is 0.16. So our model is failed at predicting animals when image color is manipulated. Model's accuracy decreased from 0.66 to 0.16."
      ],
      "metadata": {
        "id": "BXvL2BLe_yKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate test images\n",
        "manipulated_test_set, manipulated_labels = manipulate_test_images(X_test, y_test)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(manipulated_test_set, manipulated_labels_onehot, verbose=1)\n",
        "\n",
        "print(f\"Manipüle edilmiş test seti üzerindeki kayıp (loss): {loss}\")\n",
        "print(f\"Manipüle edilmiş test seti üzerindeki doğruluk (accuracy): {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmAeNOxcxZOL",
        "outputId": "08db0d87-1c7e-42a4-d1a9-a77049461945"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.1646 - loss: 5.0438\n",
            "Manipüle edilmiş test seti üzerindeki kayıp (loss): 5.03700065612793\n",
            "Manipüle edilmiş test seti üzerindeki doğruluk (accuracy): 0.1688888818025589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To overcame our model's reliance on color, applied color correction. Now model's accuracy is back to it's original level 0.66. My inference is, color correciton method is crucial part of image processing."
      ],
      "metadata": {
        "id": "bdQLxUoTsAGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_color_correction(manipulated_test_set):\n",
        "    corrected_images = []\n",
        "\n",
        "    for image in manipulated_test_set:\n",
        "        corrected_image = get_wb_images(image)\n",
        "        corrected_images.append(corrected_image)\n",
        "\n",
        "    return np.array(corrected_images)\n",
        "\n",
        "# Test setindeki manipüle edilmiş resimleri renk sabitlemesi ile düzeltme\n",
        "manipulated_test_corrected = apply_color_correction(manipulated_test_set)\n",
        "\n",
        "# Modeli manipüle edilmiş test setiyle değerlendir\n",
        "loss, accuracy = model.evaluate(manipulated_test_corrected, manipulated_labels_onehot, verbose=1)\n",
        "\n",
        "# Sonuçları yazdır\n",
        "print(f\"Manipüle edilmiş test seti üzerindeki kayıp (loss): {loss}\")\n",
        "print(f\"Manipüle edilmiş test seti üzerindeki doğruluk (accuracy): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTZ-Bqc77cM4",
        "outputId": "58ef615c-09c1-454b-f911-a0becad0cf7e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6376 - loss: 1.0816\n",
            "Manipüle edilmiş test seti üzerindeki kayıp (loss): 1.0614460706710815\n",
            "Manipüle edilmiş test seti üzerindeki doğruluk (accuracy): 0.642393171787262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image processing models could be sensitive to image color manipulations, and using techniques like color correction can help mitigate this issue and bring the performance back to normal."
      ],
      "metadata": {
        "id": "IvE-lgfjE_3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy values for different stages\n",
        "accuracies = [0.66, 0.16, 0.66]\n",
        "labels = ['Original Test Set', 'Manipulated Test Set', 'Manipulated & Corrected Test Set']\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.bar(labels, accuracies, color=['blue', 'red', 'green'])\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Model Accuracy at Different Stages')\n",
        "plt.xlabel('Test Set Type')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ANJuVaq982Xq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "85b3a6d0-8947-435d-d324-dc613f299275"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}